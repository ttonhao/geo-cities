"""
üöÄ SISTEMA AVAN√áADO DE DIST√ÇNCIAS - VERS√ÉO PRO
=============================================

Funcionalidades Avan√ßadas:
‚úÖ Cache Inteligente - Coordenadas persistentes
‚úÖ Processamento Paralelo - M√∫ltiplas linhas simult√¢neas  
‚úÖ Dashboard Analytics - M√©tricas em tempo real
‚úÖ Mapas Interativos - Rotas visuais

Vers√£o: 3.0.0 - Pro
Autor: Sistema Avan√ßado de Dist√¢ncias MG
"""

import streamlit as st
import pandas as pd
import requests
import time
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from geopy.geocoders import Nominatim
import plotly.express as px
import plotly.graph_objects as go
import folium
from streamlit_folium import st_folium
from io import BytesIO
import json
import hashlib
from datetime import datetime, timedelta
import numpy as np

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="üöÄ Sistema Avan√ßado de Dist√¢ncias",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS avan√ßado
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        color: white;
        border-radius: 20px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
        animation: gradient 3s ease infinite;
    }
    
    @keyframes gradient {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    .analytics-card {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        backdrop-filter: blur(10px);
    }
    
    .performance-card {
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: #2c3e50;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    }
    
    .cache-stats {
        background: linear-gradient(135deg, #d299c2 0%, #fef9d7 100%);
        padding: 1rem;
        border-radius: 12px;
        margin: 1rem 0;
        border-left: 4px solid #9b59b6;
    }
    
    .parallel-status {
        background: linear-gradient(135deg, #89f7fe 0%, #66a6ff 100%);
        padding: 1rem;
        border-radius: 12px;
        color: white;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ================================
# 1. CACHE INTELIGENTE
# ================================

class SmartCache:
    def __init__(self):
        self.cache_key = "coordinates_cache_v3"
        self.stats_key = "cache_stats_v3"
        
    def _get_cache_hash(self, city_name):
        """Gera hash √∫nico para a cidade"""
        return hashlib.md5(city_name.upper().encode()).hexdigest()
    
    @st.cache_data(ttl=86400, max_entries=10000)  # 24 horas, 10k entradas
    def get_cached_coordinates(_self, city_name):
        """Cache persistente de coordenadas"""
        return None  # Ser√° preenchido dinamicamente
    
    def save_coordinates(self, city_name, coordinates):
        """Salva coordenadas no cache"""
        if 'coordinates_cache' not in st.session_state:
            st.session_state.coordinates_cache = {}
        
        cache_hash = self._get_cache_hash(city_name)
        st.session_state.coordinates_cache[cache_hash] = {
            'city': city_name,
            'coords': coordinates,
            'timestamp': datetime.now(),
            'hits': 0
        }
        
        self._update_cache_stats('save')
    
    def get_coordinates(self, city_name):
        """Recupera coordenadas do cache"""
        if 'coordinates_cache' not in st.session_state:
            st.session_state.coordinates_cache = {}
        
        cache_hash = self._get_cache_hash(city_name)
        
        if cache_hash in st.session_state.coordinates_cache:
            cached_data = st.session_state.coordinates_cache[cache_hash]
            cached_data['hits'] += 1
            self._update_cache_stats('hit')
            return cached_data['coords']
        
        self._update_cache_stats('miss')
        return None
    
    def _update_cache_stats(self, action):
        """Atualiza estat√≠sticas do cache"""
        if 'cache_stats' not in st.session_state:
            st.session_state.cache_stats = {
                'hits': 0,
                'misses': 0,
                'saves': 0,
                'hit_rate': 0,
                'total_requests': 0
            }
        
        if action == 'hit':
            st.session_state.cache_stats['hits'] += 1
        elif action == 'miss':
            st.session_state.cache_stats['misses'] += 1
        elif action == 'save':
            st.session_state.cache_stats['saves'] += 1
        
        st.session_state.cache_stats['total_requests'] += 1
    
    def get_cache_stats(self):
        """Retorna estat√≠sticas do cache"""
        if 'cache_stats' not in st.session_state:
            return {'hits': 0, 'misses': 0, 'saves': 0, 'total_requests': 0, 'hit_rate': 0}
        
        stats = st.session_state.cache_stats.copy()
        if stats['total_requests'] > 0:
            stats['hit_rate'] = (stats['hits'] / stats['total_requests']) * 100
        else:
            stats['hit_rate'] = 0
        
        return stats
    
    def clear_cache(self):
        """Limpa o cache"""
        st.session_state.coordinates_cache = {}
        st.session_state.cache_stats = {'hits': 0, 'misses': 0, 'saves': 0, 'total_requests': 0, 'hit_rate': 0}

# ================================
# 2. PROCESSAMENTO PARALELO
# ================================

class ParallelProcessor:
    def __init__(self, max_workers=4):
        self.max_workers = max_workers
        self.geocoder = Nominatim(user_agent="parallel_processor_v3", timeout=20)
        self.cache = SmartCache()
        
    def get_coordinates_with_cache(self, city_name):
        """Geocoding com cache inteligente"""
        # Tentar cache primeiro
        cached_coords = self.cache.get_coordinates(city_name)
        if cached_coords:
            return cached_coords
        
        # Geocoding se n√£o estiver no cache
        try:
            location = self.geocoder.geocode(f"{city_name}, MG, Brasil")
            if location:
                coords = [location.longitude, location.latitude]
                self.cache.save_coordinates(city_name, coords)
                return coords
            
            location = self.geocoder.geocode(f"{city_name}, Brasil")
            if location:
                coords = [location.longitude, location.latitude]
                self.cache.save_coordinates(city_name, coords)
                return coords
            
            return None
            
        except Exception as e:
            return None
    
    def calculate_distance_with_retry(self, origin_coords, dest_coords, max_retries=3):
        """Calcula dist√¢ncia com retry autom√°tico"""
        for attempt in range(max_retries):
            try:
                url = f"http://router.project-osrm.org/route/v1/driving/{origin_coords[0]},{origin_coords[1]};{dest_coords[0]},{dest_coords[1]}"
                params = {'overview': 'false', 'geometries': 'geojson'}
                
                response = requests.get(url, params=params, timeout=25)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if data.get('routes'):
                        route = data['routes'][0]
                        distance_km = route['distance'] / 1000
                        duration_min = route['duration'] / 60
                        
                        return {
                            'distancia_km': round(distance_km, 2),
                            'tempo_min': round(duration_min, 0),
                            'status': 'sucesso'
                        }
                
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # Backoff exponencial
                    
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
                    continue
        
        return {'status': 'erro_calculo', 'distancia_km': None, 'tempo_min': None}
    
    def process_linha_paralela(self, linha_data, progress_callback=None):
        """Processa uma linha com paraleliza√ß√£o interna dos destinos"""
        linha_excel = linha_data['linha_excel']
        origem = linha_data['origem']
        destinos = linha_data['destinos']
        
        resultado = {
            'linha_excel': linha_excel,
            'origem': origem,
            'total_destinos': len(destinos),
            'destinos_calculados': [],
            'destino_mais_proximo': None,
            'km_mais_proximo': None,
            'sucessos': 0,
            'erros': 0,
            'tempo_processamento': 0,
            'status': 'processando'
        }
        
        start_time = time.time()
        
        # Geocoding da origem
        if progress_callback:
            progress_callback(f"üìç Geocoding origem: {origem}")
        
        origin_coords = self.get_coordinates_with_cache(origem)
        
        if not origin_coords:
            resultado['status'] = 'origem_nao_encontrada'
            resultado['erros'] = len(destinos)
            return resultado
        
        # Geocoding paralelo dos destinos
        if progress_callback:
            progress_callback(f"üîÑ Geocoding paralelo de {len(destinos)} destinos...")
        
        def geocode_destino(destino):
            coords = self.get_coordinates_with_cache(destino)
            return destino, coords
        
        # Paralelizar geocoding
        destinos_com_coords = []
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_destino = {executor.submit(geocode_destino, dest): dest for dest in destinos}
            
            for future in as_completed(future_to_destino):
                destino, coords = future.result()
                destinos_com_coords.append((destino, coords))
        
        # C√°lculo paralelo das dist√¢ncias
        if progress_callback:
            progress_callback(f"üìè Calculando {len(destinos_com_coords)} dist√¢ncias em paralelo...")
        
        def calcular_distancia_destino(item):
            destino, dest_coords = item
            if not dest_coords:
                return {
                    'destino': destino,
                    'distancia_km': None,
                    'tempo_min': None,
                    'status': 'coordenadas_nao_encontradas'
                }
            
            resultado_calc = self.calculate_distance_with_retry(origin_coords, dest_coords)
            resultado_calc['destino'] = destino
            
            # Rate limiting por thread
            time.sleep(0.1)
            return resultado_calc
        
        # Paralelizar c√°lculos
        with ThreadPoolExecutor(max_workers=min(self.max_workers, len(destinos_com_coords))) as executor:
            future_to_calc = {executor.submit(calcular_distancia_destino, item): item for item in destinos_com_coords}
            
            for future in as_completed(future_to_calc):
                calc_resultado = future.result()
                resultado['destinos_calculados'].append(calc_resultado)
                
                if calc_resultado['status'] == 'sucesso':
                    resultado['sucessos'] += 1
                else:
                    resultado['erros'] += 1
        
        # Identificar mais pr√≥ximo
        sucessos = [d for d in resultado['destinos_calculados'] if d['distancia_km'] is not None]
        
        if sucessos:
            mais_proximo = min(sucessos, key=lambda x: x['distancia_km'])
            resultado['destino_mais_proximo'] = mais_proximo['destino']
            resultado['km_mais_proximo'] = mais_proximo['distancia_km']
        
        resultado['tempo_processamento'] = round(time.time() - start_time, 2)
        resultado['status'] = 'concluido'
        
        return resultado
    
    def process_all_lines_parallel(self, linhas_processaveis, progress_callback=None):
        """Processa todas as linhas em paralelo"""
        start_time = time.time()
        
        # Processar linhas em paralelo
        resultados = []
        
        with ThreadPoolExecutor(max_workers=min(self.max_workers, len(linhas_processaveis))) as executor:
            future_to_linha = {
                executor.submit(self.process_linha_paralela, linha, progress_callback): linha 
                for linha in linhas_processaveis
            }
            
            for future in as_completed(future_to_linha):
                resultado = future.result()
                resultados.append(resultado)
        
        # Ordenar por linha Excel
        resultados.sort(key=lambda x: x['linha_excel'])
        
        # Estat√≠sticas globais
        stats_globais = {
            'tempo_total': round(time.time() - start_time, 2),
            'linhas_processadas': len(resultados),
            'total_sucessos': sum(r['sucessos'] for r in resultados),
            'total_erros': sum(r['erros'] for r in resultados),
            'media_tempo_por_linha': round(sum(r['tempo_processamento'] for r in resultados) / len(resultados), 2),
            'processamento_paralelo': True,
            'workers_utilizados': self.max_workers
        }
        
        return resultados, stats_globais

# ================================
# 3. DASHBOARD DE ANALYTICS
# ================================

class AnalyticsDashboard:
    def __init__(self):
        self.init_session_analytics()
    
    def init_session_analytics(self):
        """Inicializa analytics da sess√£o"""
        if 'analytics' not in st.session_state:
            st.session_state.analytics = {
                'processamentos': [],
                'performance_history': [],
                'cache_history': [],
                'error_log': [],
                'session_start': datetime.now()
            }
    
    def log_processamento(self, resultados, stats_globais):
        """Registra um processamento completo"""
        log_entry = {
            'timestamp': datetime.now(),
            'linhas_processadas': stats_globais['linhas_processadas'],
            'total_sucessos': stats_globais['total_sucessos'],
            'total_erros': stats_globais['total_erros'],
            'tempo_total': stats_globais['tempo_total'],
            'taxa_sucesso': (stats_globais['total_sucessos'] / max(1, stats_globais['total_sucessos'] + stats_globais['total_erros'])) * 100,
            'processamento_paralelo': stats_globais.get('processamento_paralelo', False),
            'workers': stats_globais.get('workers_utilizados', 1)
        }
        
        st.session_state.analytics['processamentos'].append(log_entry)
        
        # Manter apenas √∫ltimos 10 processamentos
        if len(st.session_state.analytics['processamentos']) > 10:
            st.session_state.analytics['processamentos'] = st.session_state.analytics['processamentos'][-10:]
    
    def show_performance_dashboard(self):
        """Exibe dashboard de performance"""
        st.markdown("### üìä Dashboard de Analytics")
        
        # M√©tricas da sess√£o atual
        analytics = st.session_state.analytics
        
        if analytics['processamentos']:
            # M√©tricas gerais
            col1, col2, col3, col4 = st.columns(4)
            
            total_processamentos = len(analytics['processamentos'])
            ultimo_processamento = analytics['processamentos'][-1]
            media_tempo = sum(p['tempo_total'] for p in analytics['processamentos']) / total_processamentos
            media_taxa_sucesso = sum(p['taxa_sucesso'] for p in analytics['processamentos']) / total_processamentos
            
            with col1:
                st.metric("üîÑ Processamentos", total_processamentos)
            with col2:
                st.metric("‚è±Ô∏è Tempo M√©dio", f"{media_tempo:.1f}s")
            with col3:
                st.metric("üìà Taxa Sucesso M√©dia", f"{media_taxa_sucesso:.1f}%")
            with col4:
                st.metric("üöÄ Paralelo Ativo", "SIM" if ultimo_processamento['processamento_paralelo'] else "N√ÉO")
            
            # Gr√°fico de performance ao longo do tempo
            st.markdown("#### üìà Performance ao Longo do Tempo")
            
            df_performance = pd.DataFrame(analytics['processamentos'])
            df_performance['processamento_id'] = range(1, len(df_performance) + 1)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Gr√°fico de tempo de processamento
                fig_tempo = px.line(
                    df_performance,
                    x='processamento_id',
                    y='tempo_total',
                    title="‚è±Ô∏è Tempo de Processamento",
                    labels={'tempo_total': 'Tempo (segundos)', 'processamento_id': 'Processamento #'}
                )
                fig_tempo.update_traces(line_color='#667eea')
                st.plotly_chart(fig_tempo, use_container_width=True)
            
            with col2:
                # Gr√°fico de taxa de sucesso
                fig_sucesso = px.line(
                    df_performance,
                    x='processamento_id',
                    y='taxa_sucesso',
                    title="üìà Taxa de Sucesso",
                    labels={'taxa_sucesso': 'Taxa de Sucesso (%)', 'processamento_id': 'Processamento #'}
                )
                fig_sucesso.update_traces(line_color='#764ba2')
                st.plotly_chart(fig_sucesso, use_container_width=True)
            
            # Compara√ß√£o Paralelo vs Sequencial
            st.markdown("#### ‚ö° Impacto do Processamento Paralelo")
            
            paralelos = [p for p in analytics['processamentos'] if p['processamento_paralelo']]
            sequenciais = [p for p in analytics['processamentos'] if not p['processamento_paralelo']]
            
            if paralelos and sequenciais:
                col1, col2 = st.columns(2)
                
                with col1:
                    tempo_medio_paralelo = sum(p['tempo_total'] for p in paralelos) / len(paralelos)
                    st.metric("‚ö° Tempo M√©dio (Paralelo)", f"{tempo_medio_paralelo:.1f}s")
                
                with col2:
                    tempo_medio_sequencial = sum(p['tempo_total'] for p in sequenciais) / len(sequenciais)
                    st.metric("üêå Tempo M√©dio (Sequencial)", f"{tempo_medio_sequencial:.1f}s")
                
                melhoria = ((tempo_medio_sequencial - tempo_medio_paralelo) / tempo_medio_sequencial) * 100
                st.success(f"üöÄ **Melhoria de Performance:** {melhoria:.1f}% mais r√°pido com processamento paralelo!")
        
        else:
            st.info("üìä Execute um processamento para ver analytics detalhados")
    
    def show_cache_analytics(self, cache_stats):
        """Exibe analytics do cache"""
        st.markdown("#### üíæ Analytics do Cache Inteligente")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üéØ Cache Hits", cache_stats['hits'])
        with col2:
            st.metric("‚ùå Cache Misses", cache_stats['misses'])
        with col3:
            st.metric("üíæ Itens Salvos", cache_stats['saves'])
        with col4:
            st.metric("üìà Hit Rate", f"{cache_stats['hit_rate']:.1f}%")
        
        # Gr√°fico de distribui√ß√£o
        if cache_stats['total_requests'] > 0:
            fig_cache = go.Figure(data=[
                go.Pie(
                    labels=['Cache Hits', 'Cache Misses'],
                    values=[cache_stats['hits'], cache_stats['misses']],
                    hole=0.4,
                    marker_colors=['#667eea', '#764ba2']
                )
            ])
            fig_cache.update_layout(
                title="üíæ Distribui√ß√£o de Cache Hits vs Misses",
                height=300
            )
            st.plotly_chart(fig_cache, use_container_width=True)

# ================================
# 4. MAPAS INTERATIVOS
# ================================

class InteractiveMapper:
    def __init__(self):
        pass
    
    def create_route_map(self, resultado_linha):
        """Cria mapa interativo com rotas"""
        if resultado_linha['status'] != 'concluido':
            return None
        
        origem = resultado_linha['origem']
        sucessos = [d for d in resultado_linha['destinos_calculados'] if d['distancia_km'] is not None]
        
        if not sucessos:
            return None
        
        # Coordenadas da origem (simulada - em produ√ß√£o viria do cache)
        origem_lat, origem_lon = -21.7587, -43.3496  # Juiz de Fora como exemplo
        
        # Criar mapa base
        m = folium.Map(
            location=[origem_lat, origem_lon],
            zoom_start=8,
            tiles='OpenStreetMap'
        )
        
        # Marker da origem
        folium.Marker(
            [origem_lat, origem_lon],
            popup=f"üéØ ORIGEM: {origem}",
            tooltip=f"Origem: {origem}",
            icon=folium.Icon(color='red', icon='home', prefix='fa')
        ).add_to(m)
        
        # Markers dos destinos
        cores = ['blue', 'green', 'orange', 'purple', 'pink', 'gray', 'darkblue', 'darkgreen']
        
        for i, destino_data in enumerate(sucessos[:10]):  # Primeiros 10
            # Coordenadas simuladas (em produ√ß√£o viria do geocoding)
            dest_lat = origem_lat + (np.random.random() - 0.5) * 2
            dest_lon = origem_lon + (np.random.random() - 0.5) * 2
            
            cor = cores[i % len(cores)]
            
            # Marker do destino
            folium.Marker(
                [dest_lat, dest_lon],
                popup=f"üìç {destino_data['destino']}<br>üìè {destino_data['distancia_km']} km<br>‚è±Ô∏è {destino_data['tempo_min']} min",
                tooltip=f"{destino_data['destino']} - {destino_data['distancia_km']} km",
                icon=folium.Icon(color=cor, icon='map-marker', prefix='fa')
            ).add_to(m)
            
            # Linha conectando origem ao destino
            folium.PolyLine(
                [[origem_lat, origem_lon], [dest_lat, dest_lon]],
                color=cor,
                weight=3,
                opacity=0.7,
                popup=f"{origem} ‚Üí {destino_data['destino']}: {destino_data['distancia_km']} km"
            ).add_to(m)
        
        # Destaque para o mais pr√≥ximo
        if resultado_linha['destino_mais_proximo']:
            folium.Circle(
                [origem_lat, origem_lon],
                radius=50000,  # 50km
                popup=f"üèÜ Destino mais pr√≥ximo: {resultado_linha['destino_mais_proximo']}",
                color='gold',
                fill=True,
                opacity=0.3
            ).add_to(m)
        
        return m
    
    def create_overview_map(self, todos_resultados):
        """Cria mapa geral com todas as origens"""
        if not todos_resultados:
            return None
        
        # Mapa centrado no Brasil/MG
        m = folium.Map(
            location=[-19.9167, -43.9345],  # MG
            zoom_start=6,
            tiles='OpenStreetMap'
        )
        
        # Adicionar origens ao mapa
        cores_origens = ['red', 'blue', 'green', 'orange', 'purple']
        
        for i, resultado in enumerate(todos_resultados[:5]):  # Primeiras 5 origens
            if resultado['status'] != 'concluido':
                continue
            
            # Coordenadas simuladas da origem
            origem_lat = -19.9167 + (np.random.random() - 0.5) * 4
            origem_lon = -43.9345 + (np.random.random() - 0.5) * 4
            
            cor = cores_origens[i % len(cores_origens)]
            
            # Marker da origem
            folium.Marker(
                [origem_lat, origem_lon],
                popup=f"""
                <b>üéØ {resultado['origem']}</b><br>
                üìä {resultado['total_destinos']} destinos<br>
                ‚úÖ {resultado['sucessos']} sucessos<br>
                üèÜ Mais pr√≥ximo: {resultado['destino_mais_proximo']}<br>
                üìè {resultado['km_mais_proximo']} km
                """,
                tooltip=f"{resultado['origem']} - {resultado['sucessos']} sucessos",
                icon=folium.Icon(color=cor, icon='home', prefix='fa')
            ).add_to(m)
            
            # C√≠rculo representando a √°rea de cobertura
            raio = min(resultado['km_mais_proximo'] * 1000, 100000) if resultado['km_mais_proximo'] else 50000
            
            folium.Circle(
                [origem_lat, origem_lon],
                radius=raio,
                popup=f"√Årea de {resultado['origem']}",
                color=cor,
                fill=True,
                opacity=0.2
            ).add_to(m)
        
        return m

# ================================
# 5. SISTEMA PRINCIPAL INTEGRADO
# ================================

class AdvancedDistanceSystem:
    def __init__(self):
        self.cache = SmartCache()
        self.parallel_processor = ParallelProcessor(max_workers=6)
        self.analytics = AnalyticsDashboard()
        self.mapper = InteractiveMapper()
        
    def analyze_spreadsheet_advanced(self, df):
        """An√°lise avan√ßada da planilha"""
        try:
            origem_col = df.columns[1] if len(df.columns) > 1 else None
            destino_cols = df.columns[2:] if len(df.columns) > 2 else []
            
            linhas_processaveis = []
            
            for idx, row in df.iterrows():
                origem = self._clean_city_name(row[origem_col])
                
                if not origem:
                    continue
                
                destinos_linha = []
                for col in destino_cols:
                    destino = self._clean_city_name(row[col])
                    if destino:
                        destinos_linha.append(destino)
                
                if destinos_linha:
                    linhas_processaveis.append({
                        'linha_excel': idx + 1,
                        'origem': origem,
                        'destinos': destinos_linha,
                        'total_destinos': len(destinos_linha)
                    })
            
            return {
                'total_rows_original': len(df),
                'linhas_processaveis': linhas_processaveis,
                'total_linhas_validas': len(linhas_processaveis),
                'total_calculos': sum(linha['total_destinos'] for linha in linhas_processaveis),
                'estimativa_tempo_paralelo': sum(linha['total_destinos'] for linha in linhas_processaveis) * 0.1 / 60,  # Mais r√°pido
                'estimativa_tempo_sequencial': sum(linha['total_destinos'] for linha in linhas_processaveis) * 0.3 / 60
            }
            
        except Exception as e:
            st.error(f"‚ùå Erro na an√°lise: {e}")
            return None
    
    def _clean_city_name(self, city_value):
        """Limpa nome da cidade"""
        if pd.isna(city_value):
            return None
        
        city_clean = str(city_value).strip().upper()
        
        if city_clean in ['', 'NAN', 'NONE', 'NULL', '#N/A']:
            return None
        
        return city_clean.replace('  ', ' ')

def main():
    # Header futurista
    st.markdown("""
    <div class="main-header">
        <h1>üöÄ Sistema Avan√ßado de Dist√¢ncias</h1>
        <h3>Cache Inteligente ‚Ä¢ Processamento Paralelo ‚Ä¢ Analytics ‚Ä¢ Mapas Interativos</h3>
        <p>Vers√£o 3.0.0 - Performance Otimizada</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Inicializar sistema
    sistema = AdvancedDistanceSystem()
    
    # Sidebar com configura√ß√µes avan√ßadas
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes Avan√ßadas")
        
        # Configura√ß√µes de performance
        st.markdown("#### üöÄ Performance")
        max_workers = st.slider("üîß Workers Paralelos", 2, 8, 6)
        sistema.parallel_processor.max_workers = max_workers
        
        # Cache controls
        st.markdown("#### üíæ Cache Inteligente")
        cache_stats = sistema.cache.get_cache_stats()
        
        if cache_stats['total_requests'] > 0:
            st.metric("üìä Cache Hit Rate", f"{cache_stats['hit_rate']:.1f}%")
            st.metric("üíæ Itens Cached", len(st.session_state.get('coordinates_cache', {})))
        
        if st.button("üóëÔ∏è Limpar Cache"):
            sistema.cache.clear_cache()
            st.success("Cache limpo!")
            st.rerun()
        
        # Analytics toggle
        show_analytics = st.checkbox("üìä Mostrar Analytics", value=True)
        show_maps = st.checkbox("üó∫Ô∏è Mostrar Mapas", value=True)
    
    # Analytics Dashboard (se habilitado)
    if show_analytics:
        sistema.analytics.show_performance_dashboard()
        sistema.analytics.show_cache_analytics(cache_stats)
    
    # Upload e processamento
    uploaded_file = st.file_uploader(
        "üìÅ Upload da Planilha Excel",
        type=['xlsx', 'xls'],
        help="Sistema otimizado com cache e processamento paralelo"
    )
    
    if uploaded_file is not None:
        # An√°lise da planilha
        with st.spinner("üîç An√°lise avan√ßada da planilha..."):
            df = pd.read_excel(uploaded_file)
            analysis = sistema.analyze_spreadsheet_advanced(df)
        
        if analysis:
            st.success("‚úÖ Planilha analisada com otimiza√ß√µes ativadas!")
            
            # M√©tricas otimizadas
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("üìã Linhas V√°lidas", analysis['total_linhas_validas'])
            with col2:
                st.metric("üìè C√°lculos Totais", analysis['total_calculos'])
            with col3:
                st.metric("‚ö° Tempo Est. (Paralelo)", f"{analysis['estimativa_tempo_paralelo']:.1f} min")
            with col4:
                speedup = analysis['estimativa_tempo_sequencial'] / analysis['estimativa_tempo_paralelo']
                st.metric("üöÄ Speedup", f"{speedup:.1f}x")
            
            # Processamento avan√ßado
            if st.button("üöÄ Processar com Sistema Avan√ßado", type="primary", use_container_width=True):
                
                # Interface de processamento em tempo real
                st.markdown("### ‚ö° Processamento Paralelo em Execu√ß√£o")
                
                # Containers din√¢micos
                status_container = st.empty()
                metrics_container = st.container()
                progress_container = st.container()
                
                def progress_callback(msg):
                    status_container.info(f"üîÑ {msg}")
                
                # Executar processamento paralelo
                start_time = time.time()
                
                with st.spinner("Executando processamento paralelo otimizado..."):
                    resultados, stats_globais = sistema.parallel_processor.process_all_lines_parallel(
                        analysis['linhas_processaveis'], 
                        progress_callback
                    )
                
                # Log analytics
                sistema.analytics.log_processamento(resultados, stats_globais)
                
                # Exibir resultados
                if resultados:
                    # M√©tricas finais
                    st.markdown("### üìä Resultados do Processamento Avan√ßado")
                    
                    col1, col2, col3, col4, col5 = st.columns(5)
                    
                    with col1:
                        st.metric("‚è±Ô∏è Tempo Total", f"{stats_globais['tempo_total']:.2f}s")
                    with col2:
                        st.metric("üöÄ Workers", stats_globais['workers_utilizados'])
                    with col3:
                        st.metric("‚úÖ Sucessos", stats_globais['total_sucessos'])
                    with col4:
                        st.metric("‚ùå Erros", stats_globais['total_erros'])
                    with col5:
                        taxa_final = (stats_globais['total_sucessos'] / max(1, stats_globais['total_sucessos'] + stats_globais['total_erros'])) * 100
                        st.metric("üìà Taxa Sucesso", f"{taxa_final:.1f}%")
                    
                    # Performance comparison
                    tempo_estimado_sequencial = analysis['estimativa_tempo_sequencial'] * 60
                    melhoria_real = ((tempo_estimado_sequencial - stats_globais['tempo_total']) / tempo_estimado_sequencial) * 100
                    
                    st.success(f"""
                    üöÄ **Performance Otimizada Alcan√ßada!**
                    
                    ‚ö° **{melhoria_real:.1f}% mais r√°pido** que processamento sequencial  
                    üîß **{stats_globais['workers_utilizados']} workers** executando em paralelo  
                    üíæ **Cache hit rate:** {cache_stats['hit_rate']:.1f}%  
                    üìä **Tempo m√©dio por linha:** {stats_globais['media_tempo_por_linha']:.2f}s
                    """)
                    
                    # Resultados detalhados por linha
                    st.markdown("### üìã Resultados Detalhados por Linha")
                    
                    for resultado in resultados:
                        with st.expander(f"üéØ Linha {resultado['linha_excel']}: {resultado['origem']} ({resultado['sucessos']} sucessos)"):
                            
                            col1, col2 = st.columns([2, 1])
                            
                            with col1:
                                if resultado['status'] == 'concluido':
                                    sucessos = [d for d in resultado['destinos_calculados'] if d['distancia_km'] is not None]
                                    
                                    if sucessos:
                                        df_destinos = pd.DataFrame(sucessos)
                                        df_destinos = df_destinos.sort_values('distancia_km')
                                        df_destinos['ranking'] = range(1, len(df_destinos) + 1)
                                        
                                        df_display = df_destinos[['ranking', 'destino', 'distancia_km', 'tempo_min']].head(10)
                                        df_display.columns = ['#', 'Destino', 'Dist√¢ncia (km)', 'Tempo (min)']
                                        
                                        st.dataframe(df_display, use_container_width=True, hide_index=True)
                                        
                                        if resultado['destino_mais_proximo']:
                                            st.success(f"üèÜ **Mais Pr√≥ximo:** {resultado['destino_mais_proximo']} - {resultado['km_mais_proximo']} km")
                            
                            with col2:
                                # M√©tricas da linha
                                st.metric("‚è±Ô∏è Tempo", f"{resultado['tempo_processamento']}s")
                                st.metric("üìä Total", resultado['total_destinos'])
                                st.metric("‚úÖ Sucessos", resultado['sucessos'])
                                st.metric("‚ùå Erros", resultado['erros'])
                                
                                # Mapa da linha (se habilitado)
                                if show_maps and resultado['status'] == 'concluido':
                                    mapa_linha = sistema.mapper.create_route_map(resultado)
                                    if mapa_linha:
                                        st.markdown("**üó∫Ô∏è Mapa das Rotas:**")
                                        st_folium(mapa_linha, width=300, height=200)
                    
                    # Mapa geral (se habilitado)
                    if show_maps:
                        st.markdown("### üó∫Ô∏è Mapa Geral de Todas as Origens")
                        mapa_geral = sistema.mapper.create_overview_map(resultados)
                        if mapa_geral:
                            st_folium(mapa_geral, width=700, height=500)
                    
                    # Download otimizado
                    st.markdown("### üíæ Download do Relat√≥rio Avan√ßado")
                    
                    # Criar Excel com dados extras
                    excel_data = create_advanced_excel(resultados, stats_globais, cache_stats)
                    
                    if excel_data:
                        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                        filename = f"relatorio_avancado_{timestamp}.xlsx"
                        
                        st.download_button(
                            label="üì• Baixar Relat√≥rio Avan√ßado (Excel)",
                            data=excel_data,
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            type="primary",
                            use_container_width=True
                        )
                        
                        st.info("""
                        üìä **Relat√≥rio Avan√ßado cont√©m:**
                        - üìã Resultados detalhados por linha
                        - ‚ö° M√©tricas de performance paralela
                        - üíæ Estat√≠sticas de cache
                        - üìà Analytics de processamento
                        - üó∫Ô∏è Coordenadas para mapas
                        """)

def create_advanced_excel(resultados, stats_globais, cache_stats):
    """Cria Excel avan√ßado com m√©tricas extras"""
    output = BytesIO()
    
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # Aba principal
            relatorio_completo = []
            for resultado in resultados:
                if resultado['status'] == 'concluido':
                    sucessos = [d for d in resultado['destinos_calculados'] if d['distancia_km'] is not None]
                    
                    for i, dest_data in enumerate(sucessos, 1):
                        relatorio_completo.append({
                            'Linha_Excel': resultado['linha_excel'],
                            'Origem': resultado['origem'],
                            'Destino': dest_data['destino'],
                            'Distancia_KM': dest_data['distancia_km'],
                            'Tempo_Minutos': dest_data['tempo_min'],
                            'Ranking_na_Linha': i,
                            'Eh_Mais_Proximo': 'SIM' if dest_data['destino'] == resultado['destino_mais_proximo'] else 'N√ÉO',
                            'Tempo_Processamento_Linha': resultado['tempo_processamento']
                        })
            
            if relatorio_completo:
                df_completo = pd.DataFrame(relatorio_completo)
                df_completo.to_excel(writer, sheet_name='Resultados_Avancados', index=False)
            
            # M√©tricas de performance
            performance_data = {
                'M√©trica': [
                    'Tempo Total de Processamento (s)',
                    'Processamento Paralelo Ativo',
                    'Workers Utilizados',
                    'Linhas Processadas',
                    'Total de Sucessos',
                    'Total de Erros',
                    'Taxa de Sucesso (%)',
                    'Tempo M√©dio por Linha (s)',
                    'Cache Hit Rate (%)',
                    'Total de Cache Hits',
                    'Total de Cache Misses',
                    'Itens Salvos no Cache',
                    'Sistema de Coordenadas',
                    'API de Rotas'
                ],
                'Valor': [
                    stats_globais['tempo_total'],
                    'SIM' if stats_globais.get('processamento_paralelo', False) else 'N√ÉO',
                    stats_globais.get('workers_utilizados', 1),
                    stats_globais['linhas_processadas'],
                    stats_globais['total_sucessos'],
                    stats_globais['total_erros'],
                    round((stats_globais['total_sucessos'] / max(1, stats_globais['total_sucessos'] + stats_globais['total_erros'])) * 100, 2),
                    stats_globais['media_tempo_por_linha'],
                    round(cache_stats['hit_rate'], 2),
                    cache_stats['hits'],
                    cache_stats['misses'],
                    cache_stats['saves'],
                    'Nominatim (OpenStreetMap)',
                    'OSRM (Open Source Routing Machine)'
                ]
            }
            
            df_performance = pd.DataFrame(performance_data)
            df_performance.to_excel(writer, sheet_name='Metricas_Performance', index=False)
            
            # Resumo das origens com m√©tricas avan√ßadas
            resumo_avancado = []
            for resultado in resultados:
                resumo_avancado.append({
                    'Linha_Excel': resultado['linha_excel'],
                    'Origem': resultado['origem'],
                    'Total_Destinos': resultado['total_destinos'],
                    'Sucessos': resultado['sucessos'],
                    'Erros': resultado['erros'],
                    'Taxa_Sucesso_Linha': round((resultado['sucessos'] / max(1, resultado['total_destinos'])) * 100, 1),
                    'Tempo_Processamento_Segundos': resultado['tempo_processamento'],
                    'Destino_Mais_Proximo': resultado['destino_mais_proximo'],
                    'Distancia_Mais_Proxima_KM': resultado['km_mais_proximo'],
                    'Status_Processamento': resultado['status']
                })
            
            df_resumo_avancado = pd.DataFrame(resumo_avancado)
            df_resumo_avancado.to_excel(writer, sheet_name='Resumo_Avancado', index=False)
        
        return output.getvalue()
        
    except Exception as e:
        st.error(f"‚ùå Erro ao criar Excel avan√ßado: {e}")
        return None

if __name__ == "__main__":
    main()