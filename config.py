 # type: ignore
"""
âš™ï¸ CONFIGURAÃ‡Ã•ES AVANÃ‡ADAS DO SISTEMA
===================================

Arquivo de configuraÃ§Ã£o para otimizar performance
baseado no hardware e necessidades especÃ­ficas.

VersÃ£o: 3.0.0
"""

import os
from dataclasses import dataclass
from typing import Dict, List, Optional

@dataclass
class CacheConfig:
    """ConfiguraÃ§Ãµes do cache inteligente"""
    ttl_hours: int = 24                    # Time-to-live em horas
    max_entries: int = 10000               # MÃ¡ximo de entradas no cache
    enable_persistence: bool = True         # Cache persistente entre sessÃµes
    auto_cleanup: bool = True              # Limpeza automÃ¡tica de entradas antigas
    hit_rate_target: float = 0.8           # Meta de hit rate (80%)

@dataclass
class ParallelConfig:
    """ConfiguraÃ§Ãµes de processamento paralelo"""
    max_workers: int = 6                   # Workers padrÃ£o
    min_workers: int = 1                   # MÃ­nimo de workers
    auto_scaling: bool = True              # Auto-scale baseado no dataset
    rate_limit_per_thread: float = 0.1     # Delay entre requisiÃ§Ãµes por thread
    timeout_seconds: int = 25              # Timeout por requisiÃ§Ã£o
    retry_attempts: int = 3                # Tentativas de retry
    backoff_factor: float = 2.0            # Fator de backoff exponencial

@dataclass
class AnalyticsConfig:
    """ConfiguraÃ§Ãµes de analytics"""
    enable_real_time: bool = True          # Analytics em tempo real
    history_limit: int = 50                # Limite de histÃ³rico de processamentos
    auto_export: bool = True               # Export automÃ¡tico de mÃ©tricas
    performance_alerts: bool = True        # Alertas de performance
    benchmark_mode: bool = False           # Modo benchmark detalhado

@dataclass
class MapConfig:
    """ConfiguraÃ§Ãµes de mapas"""
    enable_interactive: bool = True        # Mapas interativos
    default_zoom: int = 8                  # Zoom padrÃ£o
    max_markers: int = 50                  # MÃ¡ximo de markers por mapa
    route_colors: List[str] = None         # Cores das rotas
    center_lat: float = -19.9167           # Centro padrÃ£o (MG)
    center_lon: float = -43.9345           # Centro padrÃ£o (MG)
    
    def __post_init__(self):
        if self.route_colors is None:
            self.route_colors = [
                '#FF6B35', '#F7931E', '#FFD23F', '#06FFA5',
                '#118AB2', '#073B4C', '#A663CC', '#FF006E'
            ]

@dataclass
class GeocodingConfig:
    """ConfiguraÃ§Ãµes de geocoding"""
    user_agent: str = "advanced_distance_system_v3"
    timeout_seconds: int = 20              # Timeout para geocoding
    fallback_strategies: List[str] = None  # EstratÃ©gias de fallback
    brazil_priority: bool = True           # Priorizar resultados do Brasil
    mg_priority: bool = True               # Priorizar MG quando possÃ­vel
    
    def __post_init__(self):
        if self.fallback_strategies is None:
            self.fallback_strategies = [
                "{city}, MG, Brasil",
                "{city}, Brasil", 
                "{city}"
            ]

@dataclass
class RoutingConfig:
    """ConfiguraÃ§Ãµes de cÃ¡lculo de rotas"""
    api_base_url: str = "http://router.project-osrm.org"
    route_profile: str = "driving"         # driving, walking, cycling
    overview: str = "false"                # Detalhes da geometria
    alternatives: bool = False             # Rotas alternativas
    steps: bool = False                    # InstruÃ§Ãµes passo-a-passo
    annotations: bool = False              # AnotaÃ§Ãµes detalhadas

class SystemConfig:
    """ConfiguraÃ§Ã£o geral do sistema"""
    
    def __init__(self):
        self.cache = CacheConfig()
        self.parallel = ParallelConfig()
        self.analytics = AnalyticsConfig()
        self.maps = MapConfig()
        self.geocoding = GeocodingConfig()
        self.routing = RoutingConfig()
        
        # Auto-detecÃ§Ã£o de hardware
        self._detect_hardware()
        
        # Aplicar otimizaÃ§Ãµes baseadas no ambiente
        self._apply_optimizations()
    
    def _detect_hardware(self):
        """Detecta capacidades do hardware"""
        try:
            import psutil
            
            # CPU cores
            cpu_count = psutil.cpu_count(logical=True)
            
            # MemÃ³ria disponÃ­vel
            memory_gb = psutil.virtual_memory().total / (1024**3)
            
            # Ajustar workers baseado no hardware
            if cpu_count >= 8:
                self.parallel.max_workers = min(8, cpu_count - 2)
            elif cpu_count >= 4:
                self.parallel.max_workers = min(6, cpu_count - 1)
            else:
                self.parallel.max_workers = max(2, cpu_count)
            
            # Ajustar cache baseado na memÃ³ria
            if memory_gb >= 16:
                self.cache.max_entries = 15000
            elif memory_gb >= 8:
                self.cache.max_entries = 10000
            else:
                self.cache.max_entries = 5000
                
        except ImportError:
            # Psutil nÃ£o disponÃ­vel, usar defaults
            pass
    
    def _apply_optimizations(self):
        """Aplica otimizaÃ§Ãµes baseadas no ambiente"""
        
        # OtimizaÃ§Ãµes para produÃ§Ã£o
        if os.getenv('STREAMLIT_ENV') == 'production':
            self.parallel.rate_limit_per_thread = 0.2  # Mais conservador
            self.cache.ttl_hours = 48                  # Cache mais longo
            self.analytics.history_limit = 100        # Mais histÃ³rico
        
        # OtimizaÃ§Ãµes para desenvolvimento
        elif os.getenv('STREAMLIT_ENV') == 'development':
            self.parallel.rate_limit_per_thread = 0.05  # Mais agressivo
            self.cache.ttl_hours = 1                    # Cache curto para testes
            self.analytics.benchmark_mode = True        # Benchmark detalhado
    
    def get_optimized_workers(self, dataset_size: int) -> int:
        """Calcula nÃºmero Ã³timo de workers para um dataset"""
        if dataset_size <= 10:
            return min(2, self.parallel.max_workers)
        elif dataset_size <= 50:
            return min(4, self.parallel.max_workers)
        else:
            return self.parallel.max_workers
    
    def get_rate_limit(self, workers: int) -> float:
        """Calcula rate limit Ã³timo baseado no nÃºmero de workers"""
        base_rate = self.parallel.rate_limit_per_thread
        
        # Ajustar rate limit baseado no nÃºmero de workers
        if workers >= 6:
            return base_rate * 1.5  # Mais conservador com muitos workers
        elif workers <= 2:
            return base_rate * 0.5  # Mais agressivo com poucos workers
        else:
            return base_rate
    
    def export_config(self) -> Dict:
        """Exporta configuraÃ§Ã£o atual"""
        return {
            'cache': {
                'ttl_hours': self.cache.ttl_hours,
                'max_entries': self.cache.max_entries,
                'enable_persistence': self.cache.enable_persistence
            },
            'parallel': {
                'max_workers': self.parallel.max_workers,
                'rate_limit_per_thread': self.parallel.rate_limit_per_thread,
                'timeout_seconds': self.parallel.timeout_seconds
            },
            'analytics': {
                'enable_real_time': self.analytics.enable_real_time,
                'history_limit': self.analytics.history_limit
            },
            'maps': {
                'enable_interactive': self.maps.enable_interactive,
                'max_markers': self.maps.max_markers
            }
        }

# ConfiguraÃ§Ã£o global (singleton)
CONFIG = SystemConfig()

def get_config() -> SystemConfig:
    """Retorna configuraÃ§Ã£o global"""
    return CONFIG

def optimize_for_dataset(num_lines: int, total_calculations: int) -> Dict:
    """Otimiza configuraÃ§Ãµes para um dataset especÃ­fico"""
    config = get_config()
    
    # Calcular workers Ã³timos
    optimal_workers = config.get_optimized_workers(num_lines)
    
    # Calcular rate limit Ã³timo
    optimal_rate_limit = config.get_rate_limit(optimal_workers)
    
    # Estimar tempo de processamento
    time_per_calc = 0.4  # segundos base por cÃ¡lculo
    estimated_time = (total_calculations * time_per_calc) / optimal_workers
    
    return {
        'workers': optimal_workers,
        'rate_limit': optimal_rate_limit,
        'estimated_time_minutes': estimated_time / 60,
        'cache_efficiency_expected': min(0.9, num_lines / 100),  # EficiÃªncia esperada
        'memory_usage_mb': total_calculations * 0.1,  # Estimativa de uso de memÃ³ria
        'recommendations': _generate_recommendations(num_lines, total_calculations)
    }

def _generate_recommendations(num_lines: int, total_calculations: int) -> List[str]:
    """Gera recomendaÃ§Ãµes baseadas no dataset"""
    recommendations = []
    
    if num_lines > 100:
        recommendations.append("ğŸš€ Dataset grande detectado: usar mÃ¡ximo de workers")
        recommendations.append("ğŸ’¾ Ativar cache persistente para sessÃµes futuras")
    
    if total_calculations > 1000:
        recommendations.append("â±ï¸ Processamento longo esperado: considere executar em horÃ¡rios de menor rede")
        recommendations.append("ğŸ“Š Ativar benchmark mode para anÃ¡lise detalhada")
    
    if num_lines < 10:
        recommendations.append("âš¡ Dataset pequeno: usar poucos workers para evitar overhead")
        recommendations.append("ğŸ¯ Considere agrupar com outros processamentos")
    
    return recommendations

# ConfiguraÃ§Ãµes especÃ­ficas por ambiente
PRODUCTION_CONFIG = {
    'cache_ttl_hours': 48,
    'max_workers': 4,
    'rate_limit': 0.2,
    'enable_analytics': True,
    'enable_maps': True
}

DEVELOPMENT_CONFIG = {
    'cache_ttl_hours': 1,
    'max_workers': 8,
    'rate_limit': 0.05,
    'enable_analytics': True,
    'enable_maps': True,
    'benchmark_mode': True
}

TESTING_CONFIG = {
    'cache_ttl_hours': 0.1,
    'max_workers': 2,
    'rate_limit': 0.01,
    'enable_analytics': False,
    'enable_maps': False
}

def load_environment_config(env: str = 'production'):
    """Carrega configuraÃ§Ã£o especÃ­fica do ambiente"""
    global CONFIG
    
    if env == 'production':
        config_dict = PRODUCTION_CONFIG
    elif env == 'development':
        config_dict = DEVELOPMENT_CONFIG
    elif env == 'testing':
        config_dict = TESTING_CONFIG
    else:
        return CONFIG
    
    # Aplicar configuraÃ§Ãµes
    for key, value in config_dict.items():
        if hasattr(CONFIG.parallel, key):
            setattr(CONFIG.parallel, key, value)
        elif hasattr(CONFIG.cache, key.replace('cache_', '')):
            setattr(CONFIG.cache, key.replace('cache_', ''), value)
        elif hasattr(CONFIG.analytics, key.replace('enable_', '')):
            setattr(CONFIG.analytics, key.replace('enable_', ''), value)
    
    return CONFIG

if __name__ == "__main__":
    # Demo das configuraÃ§Ãµes
    config = get_config()
    
    print("âš™ï¸ CONFIGURAÃ‡Ã•ES DO SISTEMA AVANÃ‡ADO")
    print("=" * 50)
    
    print(f"ğŸš€ Processamento Paralelo:")
    print(f"   Workers mÃ¡ximos: {config.parallel.max_workers}")
    print(f"   Rate limit: {config.parallel.rate_limit_per_thread}s")
    print(f"   Timeout: {config.parallel.timeout_seconds}s")
    
    print(f"\nğŸ’¾ Cache Inteligente:")
    print(f"   TTL: {config.cache.ttl_hours} horas")
    print(f"   Max entradas: {config.cache.max_entries}")
    print(f"   Persistente: {config.cache.enable_persistence}")
    
    print(f"\nğŸ“Š Analytics:")
    print(f"   Tempo real: {config.analytics.enable_real_time}")
    print(f"   HistÃ³rico: {config.analytics.history_limit}")
    
    print(f"\nğŸ—ºï¸ Mapas:")
    print(f"   Interativos: {config.maps.enable_interactive}")
    print(f"   Max markers: {config.maps.max_markers}")
    
    # Teste de otimizaÃ§Ã£o
    print(f"\nğŸ¯ EXEMPLO DE OTIMIZAÃ‡ÃƒO:")
    print("=" * 50)
    
    optimization = optimize_for_dataset(num_lines=25, total_calculations=500)
    
    print(f"Dataset: 25 linhas, 500 cÃ¡lculos")
    print(f"Workers recomendados: {optimization['workers']}")
    print(f"Rate limit Ã³timo: {optimization['rate_limit']}s")
    print(f"Tempo estimado: {optimization['estimated_time_minutes']:.1f} min")
    print(f"EficiÃªncia cache esperada: {optimization['cache_efficiency_expected']*100:.1f}%")
    
    print(f"\nğŸ’¡ RecomendaÃ§Ãµes:")
    for rec in optimization['recommendations']:
        print(f"   {rec}")